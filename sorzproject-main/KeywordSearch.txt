# Documentación de la Lógica de Scraping de Keywords en TikTok

## 1. Estructura Principal

### Archivos Modificados
- `app/api/scraping/tiktok/route.ts`: Implementación principal del scraping
- `app/components/search-results.jsx`: Manejo del frontend y polling

## 2. Lógica de Scraping

### 2.1 Proceso de Extracción
1. **Inicialización**:
   - Recibe keywords y scraperLimit (1000-5000)
   - Valida y limpia las keywords
   - Crea un job en la base de datos

2. **Estrategia de Extracción**:
   - Divide las keywords en grupos combinados
   - Ejemplo: Para ["nike", "nike men", "nike usa"]:
     - ["nike"]
     - ["nike", "nike men"]
     - ["nike", "nike men", "nike usa"]
     - ["nike men"]
     - ["nike men", "nike usa"]
     - ["nike usa"]

3. **Proceso Iterativo**:
   - Bucle while hasta obtener suficientes resultados únicos
   - Para cada grupo:
     - Hace una llamada a Apify con el grupo
     - Espera a que termine el run
     - Obtiene y procesa los resultados
     - Actualiza el contador de resultados únicos

### 2.2 Manejo de Resultados
- Mantiene un array de resultados únicos
- Elimina duplicados basados en username
- Continúa el proceso hasta alcanzar el scraperLimit

## 3. Resultados

### 3.1 Estado Actual
- Se logró obtener más resultados que antes
- Sin embargo, no se alcanzaron los 1000 resultados únicos
- Se obtuvieron aproximadamente 400-500 resultados únicos

### 3.2 Limitaciones Identificadas
1. Apify tiene límites en la cantidad de resultados por run
2. Algunas keywords pueden no devolver resultados
3. Hay duplicados entre diferentes grupos de keywords

## 4. Mejoras Implementadas

### 4.1 Tiempos y Límites
- Aumentado el timeout a 60 minutos
- Aumentado el intervalo de polling a 30 segundos
- Implementado maxItems y maxChargedResults en Apify

### 4.2 Logging
- Logs detallados del proceso
- Seguimiento de resultados únicos
- Información de progreso en porcentaje

## 5. Próximos Pasos

### 5.1 Estrategias a Explorar
1. Aumentar el tiempo de espera entre runs
2. Modificar la forma de dividir las keywords
3. Ajustar los parámetros de búsqueda de Apify
4. Implementar paginación en los resultados

### 5.2 Optimizaciones Pendientes
1. Mejorar la eficiencia en la eliminación de duplicados
2. Implementar un sistema de reintentos más robusto
3. Optimizar la combinación de keywords
4. Mejorar el manejo de errores y recuperación

## 6. Conclusión

La implementación actual ha mejorado la cantidad de resultados obtenidos, pero aún no alcanza el objetivo de 1000 resultados únicos. Se necesitan más ajustes y optimizaciones para alcanzar este objetivo.

## 7. Métricas de Rendimiento y Costos

### 7.1 Costos y Tiempo
- **Costo Total**: $8 USD
- **Tiempo Total**: 54 minutos
- **Número de Runs**: 108
- **Tiempo Promedio por Run**: 30 segundos

### 7.2 Eficiencia de Datos
- **Resultados Únicos Objetivo**: 1,000
- **Resultados Totales Scrapeados**: ~23,000
- **Tasa de Unicidad**: ~4.3% (1,000/23,000)

### 7.3 Análisis de Eficiencia
1. **Costo por Resultado Único**: $0.008 USD
2. **Tiempo por Resultado Único**: 3.24 segundos
3. **Ratio de Desperdicio**: 95.7% (resultados duplicados o no utilizables)

### 7.4 Implicaciones
- El proceso es costoso en términos de recursos de Apify
- La tasa de unicidad es baja, indicando muchos duplicados
- El tiempo total es significativo para la cantidad de resultados únicos
- Se necesitan optimizaciones para mejorar la eficiencia y reducir costos

<ENFOQUE SIN FILTRAR:>
### Métricas del Enfoque Sin Filtrar
- **Costo Total**: $0.5 USD
- **Tiempo Total**: 2.5 minutos
- **Número de Runs**: 5
- **Tiempo Promedio por Run**: 30 segundos
- **Resultados Totales**: 1,000

### Mejoras Respecto al Enfoque Anterior
- **Mejora en Costo**: 93.75% ($8 → $0.5)
- **Mejora en Tiempo**: 95.37% (54 → 2.5 minutos)
- **Mejora en Runs**: 95.37% (108 → 5)

### Análisis de Eficiencia
- **Costo por Resultado**: $0.1 USD
- **Tiempo por Resultado**: 0.15 segundos
- **Ratio de Desperdicio**: 0%

### Beneficios
1. Proceso más rápido y económico
2. Menor número de llamadas a la API
3. Mayor eficiencia en el uso de recursos
4. Sin pérdida de datos por deduplicación