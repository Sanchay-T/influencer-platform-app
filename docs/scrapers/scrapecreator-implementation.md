# Plan de Migraci√≥n de Apify a ScrapeCreators üîÑ

## Contexto del Proyecto

Este documento detalla el plan de migraci√≥n de un sistema de scraping de TikTok que actualmente usa Apify hacia la plataforma ScrapeCreators.

### Situaci√≥n Actual
- Sistema desplegado en Vercel (con l√≠mite de 10s en endpoints)
- Usa QStash para procesamiento as√≠ncrono
- Base de datos en Supabase
- B√∫squeda por keywords en TikTok
- M√°ximo 10 keywords por b√∫squeda
- L√≠mite de 1000 resultados por b√∫squeda

### Objetivo de la Migraci√≥n
- [X] Reemplazar Apify con ScrapeCreators manteniendo la misma funcionalidad
- [X] Mantener el sistema de colas con QStash por limitaciones de Vercel
- [X] Extraer datos espec√≠ficos de videos de TikTok:
  - [X] **Informaci√≥n del creador**:
    - [X] Nombre: `author.nickname`
    - [X] ID √∫nico: `author.unique_id`
    - [X] URL del avatar: `author.avatar_medium.url_list[0]`
    - [X] N√∫mero de seguidores: `author.follower_count`
  - [X] **Hashtags**: Extra√≠dos de `text_extra` donde cada objeto con `type: 1` representa un hashtag
  - [X] **El video con sus estad√≠sticas**
    - [X] URL del video: `share_url`
    - [X] Descripci√≥n del video: `desc`
    - [X] Reproducciones: `statistics.play_count`
    - [X] Me gusta: `statistics.digg_count`
    - [X] Comentarios: `statistics.comment_count`
    - [X] Compartidos: `statistics.share_count`
  - [X] **Fecha de creaci√≥n**: `create_time` (timestamp Unix)

### Notas T√©cnicas Importantes
- La API de ScrapeCreators utiliza un sistema de paginaci√≥n basado en cursor, diferente al offset que usaba Apify
- Por ahora solo se procesa una keyword a la vez (la primera del array de keywords)
- Se ha agregado un nuevo campo `cursor` en la tabla `scraping_jobs` para manejar la paginaci√≥n
- Los resultados mantienen la misma estructura que antes para compatibilidad con el frontend existente

// 2. **Hashtags**: Extra√≠dos de `text_extra` donde cada objeto con `type: 1` representa un hashtag

// 3. **El video con sus estad√≠sticas**
  // 3.1 URL del video: `share_url`
  // 3.2 Descripci√≥n del video: `desc`
  // 3.3 Reproducciones: `statistics.play_count`
  // 3.4 Me gusta: `statistics.digg_count`
  // 3.5 Comentarios: `statistics.comment_count`
  // 3.6 Compartidos: `statistics.share_count`

// 4. **Fecha de creaci√≥n**: `create_time` (timestamp Unix)


### Consideraciones T√©cnicas
- No se requiere mantener compatibilidad con Apify
- Se debe mantener el procesamiento as√≠ncrono
- Los resultados deben seguir el mismo formato para el frontend
- Se mantiene la arquitectura de Next.js App Router

## Fase 1: Configuraci√≥n Inicial
- [ ] Configurar variables de entorno en `.env.local`:
  ```
  SCRAPECREATORS_API_KEY=your_api_key
  SCRAPECREATORS_API_URL=https://api.scrapecreators.com/v1
  ```

## Fase 2: Adaptaci√≥n de API Routes ‚úÖ
- [X] Modificar `app/api/scraping/tiktok/route.ts`:
  ```typescript
  export async function POST(req: Request) {
    // 1. Validar usuario
    // 2. Recibir keywords y campaignId
    // 3. Crear job en DB
    // 4. Encolar en QStash
  }
  ```

- [X] Actualizar `app/api/qstash/process-scraping/route.ts`:
  ```typescript
  export async function POST(req: Request) {
    // 1. Recibir jobId de QStash
    // 2. Llamar a ScrapeCreators API
    // 3. Procesar respuesta
    // 4. Actualizar job status
  }
  ```

## Fase 3: Modelo de Datos ‚úÖ
- [X] Actualizar `app/models/schema.ts` para nuevos campos:
  ```typescript
  export interface ScrapingResult {
    creatorInfo: {
      name: string;           // author.nickname
      id: string;            // author.unique_id
      avatarUrl: string;     // author.avatar_medium.url_list[0]
      followers: number;     // author.follower_count
    };
    hashtags: string[];      // text_extra[type=1]
    videoStats: {
      url: string;          // share_url
      description: string;  // desc
      plays: number;       // statistics.play_count
      likes: number;      // statistics.digg_count
      comments: number;   // statistics.comment_count
      shares: number;    // statistics.share_count
    };
    createdAt: number;    // create_time
  }
  ```

## Fase 4: Componentes Frontend
- [ ] Actualizar `app/campaigns/keyword-search/page.tsx`:
  ```typescript
  export default function KeywordSearchPage() {
    // Server Component con formulario inicial
  }
  ```

- [ ] Modificar `app/components/keyword-search/search-form.tsx`:
  ```typescript
  'use client'
  export function SearchForm() {
    // Client Component para manejo de formulario
  }
  ```

## Fase 5: Sistema de Polling y Estado
- [ ] Implementar `app/hooks/use-scraping-status.ts`:
  ```typescript
  export function useScrapingStatus(jobId: string) {
    // Hook para polling cada 3 segundos
  }
  ```

## Fase 6: Manejo de Errores y Logging
- [ ] Crear error boundaries por componente
- [ ] Implementar logging detallado
- [ ] Configurar timeouts y retries

## Diagrama de Flujo Actualizado

```mermaid
graph TD
    A[Search Form] -->|Submit| B[/api/scraping/tiktok]
    B -->|Create Job| C[Database]
    B -->|Queue| D[QStash]
    D -->|Process| E[/api/qstash/process-scraping]
    E -->|API Call| F[ScrapeCreators API]
    F -->|Response| E
    E -->|Update| C
    G[Status Hook] -->|Poll| C
    C -->|Results| H[Results Component]
```

## Notas T√©cnicas

### Endpoints
- POST `/api/scraping/tiktok`: Inicia b√∫squeda
- POST `/api/qstash/process-scraping`: Procesa con ScrapeCreators
- GET `/api/qstash/check-status`: Verifica estado

### L√≠mites y Timeouts
- Timeout de Vercel: 10 segundos
- Polling interval: 3 segundos
- M√°ximo tiempo total: 60 minutos

### Seguridad
- API Key solo en backend
- Validaci√≥n de usuarios
- Rate limiting por IP

### Manejo de Errores
- Retry autom√°tico en fallos de API
- Error boundaries en frontend
- Logging en servidor
