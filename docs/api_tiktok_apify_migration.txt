PLAN DE MIGRACIÓN: SDK APIFY A API DIRECTA
=========================================

1. CONTEXTO DEL PROBLEMA
-----------------------
Situación actual:
- Usando SDK de Apify que presenta errores consistentes
- Error principal: "Search keyword or start URLs must be provided"
- Sistema distribuido: Next.js + Vercel + QStash + Apify + Supabase
- Múltiples intentos fallidos con diferentes formatos de input

2. ARQUITECTURA ACTUAL
--------------------
a) Componentes:
   - Frontend: Next.js en Vercel
   - Base de datos: Supabase (PostgreSQL)
   - Cola de trabajos: QStash
   - Scraping: Apify (Actor: apidojo/tiktok-scraper)

b) Flujo actual:
   1. Usuario -> POST /api/scraping/tiktok
   2. API -> Crear job en DB
   3. API -> Encolar job en QStash
   4. QStash -> Llamar a /api/qstash/process-scraping
   5. Worker -> Llamar a Apify SDK
   6. Apify -> Retornar resultados
   7. Worker -> Guardar en DB

3. ARCHIVOS A MODIFICAR
---------------------
1. /lib/utils/apify.ts (NUEVO)
   - Implementar cliente HTTP para Apify
   - Manejar autenticación
   - Implementar retry strategy

2. /app/api/qstash/process-scraping/route.ts
   - Remover SDK de Apify
   - Integrar nuevo cliente HTTP
   - Actualizar manejo de errores

3. /lib/db/schema.ts
   - Sin cambios, mantener estructura actual

4. IMPLEMENTACIÓN DETALLADA
-------------------------
a) Nuevo archivo /lib/utils/apify.ts:
```typescript
import { type CreatorResult } from '@/lib/db/schema'

interface ApifyRunOptions {
  keywords: string[];
  maxItems: number;
  location?: string;
}

interface ApifyResponse {
  id: string;
  status: 'SUCCEEDED' | 'FAILED';
  datasetId?: string;
  error?: string;
}

export class ApifyClient {
  private baseUrl = 'https://api.apify.com/v2';
  private actorId = 'apidojo~tiktok-scraper';
  private token: string;

  constructor(token: string) {
    this.token = token;
  }

  async runActor(options: ApifyRunOptions): Promise<ApifyResponse> {
    const response = await fetch(`${this.baseUrl}/acts/${this.actorId}/runs`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        startUrls: options.keywords.map(k => ({
          url: `https://tiktok.com/search?q=${encodeURIComponent(k)}`
        })),
        maxItems: options.maxItems,
        location: options.location || 'US'
      })
    });

    if (!response.ok) {
      throw new Error(`Apify API error: ${response.statusText}`);
    }

    return response.json();
  }

  async getDatasetItems(datasetId: string): Promise<CreatorResult[]> {
    const response = await fetch(`${this.baseUrl}/datasets/${datasetId}/items`, {
      headers: {
        'Authorization': `Bearer ${this.token}`
      }
    });

    if (!response.ok) {
      throw new Error(`Dataset API error: ${response.statusText}`);
    }

    return response.json();
  }
}
```

b) Modificar /app/api/qstash/process-scraping/route.ts:
```typescript
import { ApifyClient } from '@/lib/utils/apify'

// ... resto del código existente ...

const apifyClient = new ApifyClient(process.env.APIFY_TOKEN!)

// Reemplazar la llamada al SDK con:
const runResponse = await apifyClient.runActor({
  keywords: job.keywords,
  maxItems: job.targetResults || 1000
});

if (runResponse.status === 'FAILED') {
  throw new Error(`Apify run failed: ${runResponse.error}`);
}

const items = await apifyClient.getDatasetItems(runResponse.datasetId!);
```

5. VERIFICACIÓN Y PRUEBAS
-----------------------
a) Herramientas necesarias:
   - Postman o similar para HTTP
   - Acceso a Vercel dashboard
   - Acceso a QStash dashboard
   - Acceso a Apify console
   - Acceso a Supabase

b) Pasos de verificación:
   1. Crear nuevo job:
      ```
      POST https://influencerplatform.vercel.app/api/scraping/tiktok
      Headers:
        Authorization: Cookies
        Content-Type: application/json
      Body:
        {
          "keywords": ["gaming", "streamer"],
          "targetResults": 1000
        }
      ```

   2. Verificar en Vercel logs:
      - Deployment exitoso
      - No hay errores 500
      - Logs muestran formato correcto

   3. Verificar en QStash:
      - Job encolado correctamente
      - No hay reintentos excesivos
      - Status 200 en procesamiento

   4. Verificar en Apify:
      - Actor ejecutado correctamente
      - Dataset generado
      - Resultados válidos

   5. Verificar en Supabase:
      - Job actualizado correctamente
      - Resultados guardados
      - No hay errores de validación

6. ROLLBACK PLAN
--------------
En caso de problemas:
1. Mantener rama antigua con SDK
2. Preparar rollback en Vercel
3. Backup de datos en Supabase
4. Documentar punto de retorno

7. MONITOREO POST-IMPLEMENTACIÓN
-----------------------------
Métricas a observar:
- Tasa de éxito de jobs
- Tiempo de procesamiento
- Uso de recursos
- Costos de API
- Errores y retries

8. DOCUMENTACIÓN ADICIONAL
------------------------
- Actualizar README.md
- Documentar nuevos endpoints
- Actualizar esquemas de API
- Documentar códigos de error

9. RECURSOS
---------------------
- Docs Apify: https://docs.apify.com/api/v2
- Docs QStash: https://docs.upstash.com/qstash

-----------------------------

Al chile, analizando todo:

1. Cambios REALMENTE necesarios:
Crear /lib/utils/apify.ts (nuevo, ~50 líneas)
Modificar /app/api/qstash/process-scraping/route.ts (solo la parte de Apify, ~20 líneas)

2. Tiempo estimado con Cursor + Claude:
10-15 minutos máximo para:
Crear el archivo apify.ts
Modificar el worker
Hacer el deploy
Probar

Lo único que realmente cambia es:
// ANTES (lo que no jala):
const input = {
  keywords: job.keywords,
  location: "US",
  maxItems: job.targetResults || 1000,
  dateRange: "DEFAULT"
}

// DESPUÉS (lo que sí va a jalar):
const input = {
  startUrls: job.keywords.map(k => ({
    url: `https://tiktok.com/search?q=${encodeURIComponent(k)}`
  })),
  maxItems: job.targetResults || 1000,
  location: "US"
}

4. Todo lo demás se mantiene igual:
Base de datos ✅ (no se toca)
QStash ✅ (no se toca)
Frontend ✅ (no se toca)
Esquemas ✅ (no se toca)

